{
  Cache<String,String> cache=null;
  MapReduceTask<String,String,Map<String,Integer>,Map<String,Integer>> task=new MapReduceTask<String,String,Map<String,Integer>,Map<String,Integer>>(cache);
  Map<String,Integer> result=task.onKeys("eviction","hashing","L1").mappedWith(new Mapper<String,String,Map<String,Integer>>(){
    @Override public Map<String,Integer> map(    String key,    String value){
      Map<String,Integer> counts=new HashMap<String,Integer>();
      StringTokenizer tz=new StringTokenizer(value);
      while (tz.hasMoreTokens()) {
        String word=tz.nextToken();
        Integer count=counts.get(word);
        if (count == null) {
          count=counts.put(word,1);
        }
 else {
          counts.put(word,count++);
        }
      }
      return counts;
    }
  }
).reducedWith(new Reducer<Map<String,Integer>,Map<String,Integer>>(){
    @Override public Map<String,Integer> reduce(    Map<String,Integer> mapResult,    Map<String,Integer> previousReduced){
      if (previousReduced != null && mapResult != null) {
        for (        Entry<String,Integer> e : mapResult.entrySet()) {
          if (previousReduced.containsKey(e.getKey())) {
            previousReduced.put(e.getKey(),e.getValue() + previousReduced.get(e.getKey()));
          }
 else {
            previousReduced.put(e.getKey(),e.getValue());
          }
        }
      }
      return previousReduced;
    }
  }
).collate(new WordCountCollator());
  for (  Entry<String,Integer> e : result.entrySet()) {
    System.out.println("For word " + e.getKey() + " count in all traversed documents is "+ e.getValue());
  }
}
