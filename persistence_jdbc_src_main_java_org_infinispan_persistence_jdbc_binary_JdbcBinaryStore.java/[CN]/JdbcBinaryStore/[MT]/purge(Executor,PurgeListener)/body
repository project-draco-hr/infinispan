{
  Connection conn=null;
  PreparedStatement ps=null;
  ResultSet rs=null;
  Set<Bucket> expiredBuckets=new HashSet<Bucket>();
  final int batchSize=100;
  ExecutorCompletionService<Void> ecs=new ExecutorCompletionService<Void>(threadPool);
  Set<Bucket> emptyBuckets=new HashSet<Bucket>(batchSize);
  int taskCount=0;
  try {
    try {
      String sql=tableManipulation.getSelectExpiredRowsSql();
      conn=connectionFactory.getConnection();
      ps=conn.prepareStatement(sql);
      ps.setLong(1,ctx.getTimeService().wallClockTime());
      rs=ps.executeQuery();
      while (rs.next()) {
        Integer bucketId=rs.getInt(2);
        if (immediateLockForWriting(bucketId)) {
          if (log.isTraceEnabled()) {
            log.tracef("Adding bucket keyed %s for purging.",bucketId);
          }
          Bucket bucket;
          InputStream binaryStream=rs.getBinaryStream(1);
          bucket=unmarshallBucket(binaryStream);
          bucket.setBucketId(bucketId);
          expiredBuckets.add(bucket);
          if (expiredBuckets.size() == batchSize) {
            ecs.submit(new BucketPurger(expiredBuckets,task,ctx.getMarshaller(),conn,emptyBuckets));
            taskCount++;
            expiredBuckets=new HashSet<Bucket>(batchSize);
          }
        }
 else {
          if (log.isTraceEnabled()) {
            log.tracef("Could not acquire write lock for %s, this won't be purged even though it has expired elements",bucketId);
          }
        }
      }
      if (!expiredBuckets.isEmpty())       ecs.submit(new BucketPurger(expiredBuckets,task,ctx.getMarshaller(),conn,emptyBuckets));
    }
 catch (    Exception ex) {
      releaseLocks(expiredBuckets);
      log.failedClearingJdbcCacheStore(ex);
      throw new CacheLoaderException("Failed clearing JdbcBinaryStore",ex);
    }
 finally {
      JdbcUtil.safeClose(ps);
      JdbcUtil.safeClose(rs);
    }
    try {
      PersistenceUtil.waitForAllTasksToComplete(ecs,taskCount);
    }
 catch (    CacheLoaderException e) {
      releaseLocks(emptyBuckets);
    }
    if (emptyBuckets.isEmpty())     return;
    if (log.isTraceEnabled()) {
      log.tracef("About to remove empty buckets %s",emptyBuckets);
    }
    try {
      String sql=tableManipulation.getDeleteRowSql();
      ps=conn.prepareStatement(sql);
      int deletionCount=0;
      for (      Bucket bucket : emptyBuckets) {
        ps.setString(1,bucket.getBucketIdAsString());
        ps.addBatch();
        deletionCount++;
        if (deletionCount % batchSize == 0) {
          if (log.isTraceEnabled()) {
            log.tracef("Flushing deletion batch, total deletion count so far is %d",deletionCount);
          }
          ps.executeBatch();
        }
      }
      if (deletionCount % batchSize != 0) {
        int[] batchResult=ps.executeBatch();
        if (log.isTraceEnabled()) {
          log.tracef("Flushed the batch and received following results: %s",Arrays.toString(batchResult));
        }
      }
    }
 catch (    Exception ex) {
      log.failedClearingJdbcCacheStore(ex);
      throw new CacheLoaderException("Failed clearing JdbcBinaryStore",ex);
    }
 finally {
      releaseLocks(emptyBuckets);
      JdbcUtil.safeClose(ps);
    }
  }
  finally {
    connectionFactory.releaseConnection(conn);
  }
}
