{
  final Listener l=testListenerClassValidity(listener.getClass());
  final UUID generatedId=UUID.randomUUID();
  final CacheMode cacheMode=config.clustering().cacheMode();
  FilterIndexingServiceProvider indexingProvider=null;
  boolean foundMethods=false;
  if (filter instanceof IndexedFilter) {
    IndexedFilter indexedFilter=(IndexedFilter)filter;
    indexingProvider=findIndexingServiceProvider(indexedFilter);
    if (indexingProvider != null) {
      DelegatingCacheInvocationBuilder builder=new DelegatingCacheInvocationBuilder(indexingProvider);
      builder.setIncludeCurrentState(l.includeCurrentState()).setClustered(l.clustered()).setOnlyPrimary(l.clustered() ? cacheMode.isDistributed() : l.primaryOnly()).setObservation(l.clustered() ? Listener.Observation.POST : l.observation()).setFilter(filter).setConverter(converter).setIdentifier(generatedId).setClassLoader(classLoader);
      foundMethods=validateAndAddListenerInvocations(listener,builder);
      builder.registerListenerInvocations();
    }
  }
  if (indexingProvider == null) {
    CacheInvocationBuilder builder=new CacheInvocationBuilder();
    builder.setIncludeCurrentState(l.includeCurrentState()).setClustered(l.clustered()).setOnlyPrimary(l.clustered() ? cacheMode.isDistributed() : l.primaryOnly()).setObservation(l.clustered() ? Listener.Observation.POST : l.observation()).setFilter(filter).setConverter(converter).setIdentifier(generatedId).setClassLoader(classLoader);
    foundMethods=validateAndAddListenerInvocations(listener,builder);
  }
  if (foundMethods && l.clustered()) {
    if (l.observation() == Listener.Observation.PRE) {
      throw log.clusterListenerRegisteredWithOnlyPreEvents(listener.getClass());
    }
 else     if (cacheMode.isInvalidation()) {
      throw new UnsupportedOperationException("Cluster listeners cannot be used with Invalidation Caches!");
    }
 else     if (cacheMode.isDistributed()) {
      clusterListenerIDs.put(listener,generatedId);
      EmbeddedCacheManager manager=cache.getCacheManager();
      Address ourAddress=manager.getAddress();
      List<Address> members=manager.getMembers();
      if (members != null && members.size() > 1) {
        DistributedExecutionCompletionService decs=new DistributedExecutionCompletionService(distExecutorService);
        if (trace) {
          log.tracef("Replicating cluster listener to other nodes %s for cluster listener with id %s",members,generatedId);
        }
        Callable callable=new ClusterListenerReplicateCallable(generatedId,ourAddress,filter,converter,l.sync());
        for (        Address member : members) {
          if (!member.equals(ourAddress)) {
            decs.submit(member,callable);
          }
        }
        for (int i=0; i < members.size() - 1; ++i) {
          try {
            decs.take().get();
          }
 catch (          InterruptedException e) {
            throw new CacheListenerException(e);
          }
catch (          ExecutionException e) {
            Throwable cause=e.getCause();
            if (!(cause instanceof SuspectException)) {
              throw new CacheListenerException(cause);
            }
          }
        }
        int extraCount=0;
        List<Address> membersAfter=manager.getMembers();
        for (        Address member : membersAfter) {
          if (!members.contains(member) && !member.equals(ourAddress)) {
            if (trace) {
              log.tracef("Found additional node %s that joined during replication of cluster listener with id %s",member,generatedId);
            }
            extraCount++;
            decs.submit(member,callable);
          }
        }
        for (int i=0; i < extraCount; ++i) {
          try {
            decs.take().get();
          }
 catch (          InterruptedException e) {
            throw new CacheListenerException(e);
          }
catch (          ExecutionException e) {
            throw new CacheListenerException(e);
          }
        }
      }
    }
  }
  QueueingSegmentListener handler=segmentHandler.remove(generatedId);
  if (handler != null) {
    if (trace) {
      log.tracef("Listener %s requests initial state for cache",generatedId);
    }
    try (CacheStream<CacheEntry<K,V>> entryStream=cache.getAdvancedCache().cacheEntrySet().stream()){
      Stream<CacheEntry<K,V>> usedStream=entryStream.segmentCompletionListener(handler);
      if (filter instanceof CacheEventFilterConverter && (filter == converter || converter == null)) {
        usedStream=CacheFilters.filterAndConvert(usedStream,new CacheEventFilterConverterAsKeyValueFilterConverter<>((CacheEventFilterConverter<K,V,V>)filter));
      }
 else {
        usedStream=filter == null ? usedStream : usedStream.filter(CacheFilters.predicate(new CacheEventFilterAsKeyValueFilter<>(filter)));
        usedStream=converter == null ? usedStream : usedStream.map(CacheFilters.function(new CacheEventConverterAsConverter(converter)));
      }
      Iterator<CacheEntry<K,V>> iterator=usedStream.iterator();
      while (iterator.hasNext()) {
        CacheEntry<K,V> entry=iterator.next();
        Object value=handler.markKeyAsProcessing(entry.getKey());
        if (value == BaseQueueingSegmentListener.REMOVED) {
          continue;
        }
        raiseEventForInitialTransfer(generatedId,entry,l.clustered());
        handler.notifiedKey(entry.getKey());
      }
    }
     Set<CacheEntry> entries=handler.findCreatedEntries();
    for (    CacheEntry entry : entries) {
      raiseEventForInitialTransfer(generatedId,entry,l.clustered());
    }
    if (trace) {
      log.tracef("Listener %s initial state for cache completed",generatedId);
    }
    handler.transferComplete();
  }
}
