import re
import os
from urllib.request import Request, urlopen
'\n    Finds broken links in documentation. Takes ~13 minutes. Run from root infinispan directory.\n'
rootDir = 'documentation/target/generated-docs/'
badUrls = 0
urls = dict()
for (dirName, subdirList, fileList) in os.walk(rootDir):
    for file in fileList:
        if file.endswith('.html'):
            for url in findUrls(''.join(open((dirName + file)).readlines())):
                if (url.rfind('http://localhost') != (-1)):
                    continue
                if (not urls.__contains__(url)):
                    urls.update({url: set(), })
                urls.get(url).add((dirName + file))
for url in urls.keys():
    if isBad(url):
        print (url, urls.get(url))
        badUrls += 1
print ('Number of unique URLS checked: ', len(urls))
print ('Number of bad URLs: ', badUrls)
